{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We use tensorflow and keras to build our model.\n",
        "From keras, we use the ImageDataGenerator class to import the images."
      ],
      "metadata": {
        "id": "seaFNgo4GnDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "eaaVu4UPGqy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by processing our data (images) so that we can train our model on it."
      ],
      "metadata": {
        "id": "y-Za5CUNHDvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the training images and the testing images.\n",
        "We apply feature scaling to both the training set and the test set.\n",
        "Additionally, for the training set, we apply various augmentations to the images to increase the variability."
      ],
      "metadata": {
        "id": "_xt5G8TvHWse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "test_data_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "directory_to_train_images = \"path\" #make this the path of the training images\n",
        "directory_to_test_images = \"path\"#make this the path of the testing images\n",
        "\n",
        "training_set = train_data_gen.flow_from_directory(directory_to_train_images, target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
        "test_set = test_data_gen.flow_from_directory(directory_to_test_images, target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
        "# target_size specifies the pixel resolution of the images that we want to train on. Reducing this can speed up the training process."
      ],
      "metadata": {
        "id": "nrOYCwSHHc14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start building our model by first adding the convolutional layer."
      ],
      "metadata": {
        "id": "3dnQ6FRxJ9_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "ad5C0lFHK5pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we do Max Pooling."
      ],
      "metadata": {
        "id": "4-68N8WmLFOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size= 2 , strides = 2))"
      ],
      "metadata": {
        "id": "4Zm6YGinLIDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We add another convolutional layer and do Max Pooling."
      ],
      "metadata": {
        "id": "VNufmAqnLLEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"
      ],
      "metadata": {
        "id": "kHlp4Cx_LR5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert the image matrix to a vector by applying flattening."
      ],
      "metadata": {
        "id": "KezVP7hKLXMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "cAl8TNCMLblj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the convolution, we connect to a fully connected layer system."
      ],
      "metadata": {
        "id": "GB0wM5USLh_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))"
      ],
      "metadata": {
        "id": "FJCfstsnLprX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we add the output layer."
      ],
      "metadata": {
        "id": "IUx5cD6qLwax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "jjdDwaz0L3um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin training the model."
      ],
      "metadata": {
        "id": "ORrsCXH3L9sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "id": "41KPzeQ9L_8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a prediction."
      ],
      "metadata": {
        "id": "CB6jDPjKMxAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('path to test image', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image/255.0)"
      ],
      "metadata": {
        "id": "ChdFhrjqMzPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}